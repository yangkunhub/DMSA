seed: 2022
num_epochs: 150
eval_interval: 1
eval_only: 0

lr_pow: 0.5



lr: 0.00001

optimizer: adam
weight_decay: 0.0005

dataset:
  num_workers: 4
  root_dir_pseudo_label: train/pseudo_label
  root_dir_cls_feat: train/cls_feat
  root_dir_pascalvoc: data/PascalVOC_AUG
  repeat: 20
  resize: 320
  pseudo_label_size: 40
  train_batch_size: 512            
  
  val_batch_size: 16
  split: train
  range_start: -1
  range_end: -1
model:
  teacher_update_interval: 5,5,5,5,4,4,4,4,4,3
  bootstrapping_start_epoch: 5
#  teacher_update_interval: 5,5,5,5,4,4,4,4,3,3
#  bootstrapping_start_epoch: 5
  loss:
#    weights: 1,0.3,1
    weights: 0,1,0.3,1
  encoder:
    arch: vit_small
    patch_size: 8
    pretrained_weight: weight/dino/dino_deitsmall8_pretrain.pth
#    arch: vit_base
#    patch_size: 8
#    pretrained_weight: weight/dino/dino_vitbase8_pretrain.pth   
    fix: 1
    lr_scale: 0.1
  decoder:
    pretrained_weight: -1
    n_things: 20
    n_stuff: 0
